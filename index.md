---
layout: default
---

## Applied Geometry, Algebra, and Topology in Edinburgh (AGATE)

AGATE is an informal seminar for anyone at the University of Edinburgh who is interested in applied aspects (broadly construed) of geometry, algebra and topology. AGATE's remit spans topics including algebraic statistics, geometric deep learning, and topological data analysis. The seminar is open to computational, theoretical and statistical research as well as domain-specific applications.

**When:** Wednesdays 15:05 to 16:00  
**Spring 2025 Location:** 2.11 [Appleton Tower](https://maps.app.goo.gl/zvDpZfULBhZHFmYbA)  

**Organizers:** [Djordje Mihajlovic](https://djpm.xyz/), [Siddharth Setlur](https://siddharthsetlur.github.io/), [Darrick Lee](https://darricklee.com/), and [Emily Roff](https://www.maths.ed.ac.uk/~emilyroff/)  

<!-- For the first semester, all talks will be by internal speakers. We welcome research talks and expository talks, by faculty, postdocs and students. You could tell us about your own latest paper, or something you've just read and found exciting. You could tell us the story of an interdisciplinary collaboration (what worked? what didn't?). Or you might like to give a "What is...?"-style introduction to your broad area of research. To propose a talk, email Sjoerd, Darrick or Emily. -->

To join the mailing list, send an email to sympa at mlist.is.ed.ac.uk with nothing in the subject line and in the message body put the following:

>SUBSCRIBE agate-seminar [your name]\
>QUIT

### Spring 2025 Talks

<nobr><b>Feb. 12</b>  &nbsp; <a href="https://sites.google.com/view/kelly-maggs">Kelly Maggs (MPI-CBG)</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Feb. 19</b>  &nbsp; <a href="https://users.math.msu.edu/users/weig/">Guowei Wei (Michigan State University, online)</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Feb. 26</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Mar. 5</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Mar. 12</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Mar. 19</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Mar. 26</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<nobr><b>Apr. 2</b>  &nbsp; <a href="INSERT URL HERE">TBA</a></nobr>
<details style="margin-bottom:10px">
<summary><b>TBA</b></summary>
<p style="margin-left:30px;"> TBA</p>
</details>

<br>
<br>

### Autumn 2024 Talks

<nobr><b>Oct. 2</b>  &nbsp; <a href="https://darricklee.com/">Darrick Lee</a></nobr>
<details style="margin-bottom:10px">
<summary><b>Path Signatures in Machine Learning </b></summary>
<p style="margin-left:30px;"> The path signature is a way to represent a path as an infinite sequence of tensors. We provide a high level introduction to signatures, highlighting the algebraic and geometric aspects of this construction, and discuss how this can be used to study sequences (time series) in machine learning.</p>
</details>


<nobr><b>Oct. 9</b>  &nbsp; No Seminar  
 
<br>
<br>

<nobr><b>Oct. 16</b>  &nbsp; <a href="https://homepages.inf.ed.ac.uk/amos/">Amos Storkey</a></nobr>
<details style="margin-bottom:10px">
<summary><b>Topological and Geometric Elements in Modern Deep Learning - Benefits and Challenges</b></summary>
<p style="margin-left:30px;"> This talk will take a simple introduction to machine learning, especially as used in computer vision. We then go on to see the different ways issues of geometry and topology turn up and are handled within the field. We examine the promise, in terms of generalisation, that building geometric understanding adds to a model. At the same time we recognise the challenges that imposing a rigid abstract geometry on a real world space can bring. I will give one example of our work decomposing structure and motion using a Hamiltonian model structure, before opening things up for discussion as to what the future opportunities are.</p>
</details>


<nobr><b>Oct. 23</b>  &nbsp; <a href="https://alisomia.github.io/website/">Ting Lin</a></nobr> (Peking University)
<br>
<span style="color: red;"><b>(Different Location: 2.14 <a href="    ">Appleton Tower</a>)</b></span> 
<details style="margin-bottom:10px">
<summary><b>Universal Approximation Properties of Deep Neural Networks: A Control Theory Perspective</b></summary>
<p style="margin-left:30px;"> In this talk, I will discuss the approximation properties of deep neural networks, with a particular focus on residual-type structures, a popular architecture in deep learning. We will conceptualize ResNet as a continuous control system, specifically as a parametric dynamical system. Based on this framework, we will explore the universal approximation and interpolation properties of deep neural networks. We show that any nonlinear activation function can have universal approximation property. Furthermore, we will discuss extensions to symmetric cases, including permutation and translation invariance, which are useful in scientific computing. This is based on joint work with Jingpu Cheng (NUS), Qianxiao Li (NUS), and Zuowei Shen (NUS).</p>
</details>

<nobr><b>Oct. 30</b>  &nbsp; <a href="https://sites.google.com/view/danielwindisch">Daniel Windisch</a></nobr>
<details style="margin-bottom:10px">
<summary><b>Real Algebraic Geometry for Games and their Equilibria</b></summary>
<p style="margin-left:30px;"> The classical notion of Nash equilibria imposes the somewhat unnatural assumption of independent non-cooperative acting on the players of a game. In 2005, the philosopher Wolfgang Spohn introduced a new concept, called dependency equilibria, that also takes into consideration cooperation of the players. Dependency equilibria are, however, much more involved from a mathematical viewpoint.
 
This talk will give the necessary background in game theory and will show how basic (real) algebraic geometry can be used to study dependency equilibria and game theoretical questions in general. It is based on joint work with Irem Portakal.</p>
</details>

<nobr><b>Nov. 6</b>  &nbsp; <a href="https://kaibohu.github.io/">Kaibo Hu</a></nobr>
<details style="margin-bottom:10px">
<summary><b>The Bernstein-Gelfand-Gelfand (BGG) machinery and applications</b></summary>
<p style="margin-left:30px;">  In this talk, we first review the de Rham complex and the finite element exterior calculus, a cohomological framework for structure-preserving discretisation of PDEs. From de Rham complexes, we derive other complexes with applications in elasticity, geometry and general relativity. Algebraic structures (information on cohomology) imply a number of analytic results, such as the Hodge-Helmholtz decomposition, Poincaré-Korn inequalities and compactness. The derivation, inspired by the Bernstein-Gelfand-Gelfand (BGG) construction, also provides a general machinery to establish results for tensor-valued problems (e.g., elasticity) from de Rham complexes (e.g., electromagnetism and fluid mechanics). We discuss some applications in this direction, including the construction of bounded homotopy operators (Poincaré integrals) and finite elements.</p>
</details>

<nobr><b>Nov. 13</b>  &nbsp; <a href="https://www.maths.ed.ac.uk/~prd/index.html">Patrick Rubin-Delanchy</a></nobr>
<br>
<span style="color: red;"><b>(Different Time: 16:05 - 17:00)</b></span>
<details style="margin-bottom:10px">
<summary><b>What makes a good embedding?</b></summary>
<p style="margin-left:30px;"> Embeddings are continuous vector representations of entities, such as words or nodes, perhaps most widely known for their role in modern AI systems such as large language models.
 
In this talk I consider a different goal, which is statistical analysis, or the creation of knowledge. An embedding is an instrument which allows us to observe complex, unstructured, or otherwise intractable data, in a way that we can use.
 
In embeddings, simple statistical models are tenable; concepts like similarity, or trend, have a `shape’; abstract notions such as political opinion, the health of a patient, the function of a cell, can be made geometric and measurable; and we can uncover truths that could have seemed completely absent from the raw data.
 
I illustrate these points with new theory connecting statistical models, embeddings and the manifold hypothesis, and with motivating problems in science, security, and recent work with Southmead hospital at Bristol.
 
We welcome feedback on our codebase, pyemb, a work in progress implementing these ideas: https://pyemb.github.io/pyemb/html/index.html</p>
</details>

<nobr><b>Nov. 20</b>  &nbsp; <a href="https://www.linkedin.com/in/alexdkeros/">Alexandros Keros</a></nobr>
<details style="margin-bottom:10px">
<summary><b>Understanding and navigating the self-assembly of nanoparticles</b></summary>
<p style="margin-left:30px;"> Material synthesis though nanoparticle self-assembly enables the creation of specialized structures with transformative applications in engineering and biology. However, efficient and robust control of the assembly process, and prediction of macro-scale properties, are obstructed by the inherent stochasticity and complexity of particle dynamics. I will review topological and geometric methods for characterising particle configurations in the context of material science, and explore learning and control approaches for steering their dynamics.</p>
</details>

<nobr><b>Nov. 27</b>  &nbsp; <a href="https://homepages.inf.ed.ac.uk/rsarkar/">Rik Sarkar</a></nobr>
<details style="margin-bottom:10px">
<summary><b>Hyperbolic representation of trees and applications in machine learning</b></summary>
<p style="margin-left:30px;"> Hyperbolic geometry has recently become an increasingly important topic in machine learning due to its usefulness in representing hierarchies, graphs and other types of non-euclidean data. In this talk we will discuss hyperbolic geometry and a theorem that any tree can be embedded in the hyperbolic plane with arbitrarily low distortion. Then we will review how similar ideas are used in several areas of machine learning. </p>
</details>


